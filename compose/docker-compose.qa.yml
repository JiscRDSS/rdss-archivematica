---
version: "2"

volumes:

  # Internal Named Volumes
  # These are not accessible outside of the docker host and are maintained by
  # Docker.

  # External Named Volumes
  # These are intended to be accessible beyond the docker host (e.g. via NFS).
  # They use bind mounts to mount a specific "local" directory on the docker
  # host - the expectation being that these directories are actually mounted
  # filesystems from elsewhere.
  archivematica_autotools_data:
    external:
      name: "${COMPOSE_PROJECT_NAME}_am-autotools-data"
  archivematica_pipeline_data:
    external:
      name: "${COMPOSE_PROJECT_NAME}_am-pipeline-data"
  archivematica_storage_service_location_data:
    external:
      name: "${COMPOSE_PROJECT_NAME}_am-ss-location-data"
  archivematica_storage_service_staging_data:
    external:
      name: "${COMPOSE_PROJECT_NAME}_am-ss-staging-data"
  arkivum-storage:
    external:
      name: "${COMPOSE_PROJECT_NAME}_arkivum-storage"
  elasticsearch_data:
    external:
      name: "${COMPOSE_PROJECT_NAME}_elasticsearch-data"
  jisc-test-research-data:
    external:
      name: "${COMPOSE_PROJECT_NAME}_jisc-test-research-data"
  mysql_data:
    external:
      name: "${COMPOSE_PROJECT_NAME}_mysql_data"
  nextcloud_data:
    external:
      name: "${COMPOSE_PROJECT_NAME}_nextcloud-data"
  nextcloud_themes:
    external:
      name: "${COMPOSE_PROJECT_NAME}_nextcloud-themes"

services:

  # TODO Move this to dev. For QA we should use AWS RDS instead.
  mysql:
    image: "percona:5.6"
    user: "mysql"
    environment:
      MYSQL_ROOT_PASSWORD: "12345"
    volumes:
      - "${VOL_BASE}/dev/etc/mysql/my.cnf:/etc/mysql/my.cnf:ro"
      - "mysql_data:/var/lib/mysql"
    expose:
      - "3306"

  # TODO Move this to dev. For QA we should use AWS ElasticSearch instead.
  elasticsearch:
    image: "elasticsearch:1.7-alpine"
    command: "elasticsearch -Des.node.name=TestNode -Des.network.host=0.0.0.0"
    environment:
      - "ES_MIN_MEM=${ES_HEAP_SIZE}"
      - "ES_MAX_MEM=${ES_HEAP_SIZE}"
    privileged: yes
    volumes:
      - "elasticsearch_data:/usr/share/elasticsearch/data"
    expose:
      - "9200"

  # TODO Move this to dev. For QA we should use AWS RDS instead.
  redis:
    image: "redis:3.2-alpine"
    command: '--save "" --appendonly no'  # Persistency disabled
    user: "redis"
    expose:
      - "6379"

  gearmand:
    image: "artefactual/gearmand:1.1.15-alpine"
    command: "--queue-type=redis --redis-server=redis --redis-port=6379"
    user: "gearman"
    expose:
      - "4730"
    links:
      # TODO Replace this with reference to AWS RDS hosted Redis
      - "redis"

  fits:
    image: "artefactual/fits-ngserver:0.8.4"
    expose:
      - "2113"
    volumes:
      - "archivematica_pipeline_data:/var/archivematica/sharedDirectory:rw"

  clamavd:
    image: "artefactual/clamav:latest"
    expose:
      - "3310"
    volumes:
      - "archivematica_pipeline_data:/var/archivematica/sharedDirectory:ro"

  nginx:
    image: "nginx:stable-alpine"
    volumes:
      - "${VOL_BASE}/qa/etc/nginx/nginx.conf:/etc/nginx/nginx.conf:ro"
      - "${VOL_BASE}/qa/etc/nginx/incs/:/etc/nginx/incs/:ro"
      - "${VOL_BASE}/qa/etc/nginx/conf.d/archivematica.conf:/etc/nginx/conf.d/archivematica.conf:ro"
      - "${VOL_BASE}/qa/etc/nginx/conf.d/default.conf:/etc/nginx/conf.d/default.conf:ro"
    expose:
      - "80"
      - "8000"
    ports:
      - "80"
      - "8000"

  archivematica-automation-tools:
    image: '${REGISTRY}archivematica-automation-tools:${AM_AUTOTOOLS_VERSION}'
    environment:
      AM_TOOLS_TRANSFER_AM_API_KEY: "test"
      AM_TOOLS_TRANSFER_AM_URL: "http://archivematica-dashboard:8000"
      AM_TOOLS_TRANSFER_AM_USER: "test"
      AM_TOOLS_TRANSFER_SOURCE_DESCRIPTION: "automated workflow"
      AM_TOOLS_TRANSFER_SS_API_KEY: "test"
      AM_TOOLS_TRANSFER_SS_URL: "http://archivematica-storage-service:8000"
      AM_TOOLS_TRANSFER_SS_USER: "test"
    volumes:
      - "archivematica_pipeline_data:/var/archivematica/sharedDirectory"
      - "archivematica_autotools_data:/var/archivematica/automation-tools"
    links:
      - "archivematica-dashboard"
      - "archivematica-storage-service"

  archivematica-mcp-server:
    image: '${REGISTRY}archivematica-mcp-server:${AM_MCPSERVER_VERSION}'
    environment:
      DJANGO_SECRET_KEY: "12345"
      DJANGO_SETTINGS_MODULE: "settings.common"
      ARCHIVEMATICA_MCPSERVER_CLIENT_USER: "archivematica"
      ARCHIVEMATICA_MCPSERVER_CLIENT_PASSWORD: "demo"
      ARCHIVEMATICA_MCPSERVER_CLIENT_HOST: "mysql"
      ARCHIVEMATICA_MCPSERVER_CLIENT_DATABASE: "MCP"
      ARCHIVEMATICA_MCPSERVER_MCPSERVER_MCPARCHIVEMATICASERVER: "gearmand:4730"
    volumes:
      - "archivematica_pipeline_data:/var/archivematica/sharedDirectory:rw"
    links:
      # TODO Replace this with reference to AWS RDS hosted MySQL for QA
      - "mysql"
      - "gearmand"

  archivematica-mcp-client:
    image: '${REGISTRY}archivematica-mcp-client:${AM_MCPCLIENT_VERSION}'
    environment:
      DJANGO_SECRET_KEY: "12345"
      DJANGO_SETTINGS_MODULE: "settings.common"
      NAILGUN_SERVER: "fits"
      NAILGUN_PORT: "2113"
      ARCHIVEMATICA_MCPCLIENT_CLIENT_USER: "archivematica"
      ARCHIVEMATICA_MCPCLIENT_CLIENT_PASSWORD: "demo"
      ARCHIVEMATICA_MCPCLIENT_CLIENT_HOST: "mysql"
      ARCHIVEMATICA_MCPCLIENT_CLIENT_DATABASE: "MCP"
      ARCHIVEMATICA_MCPCLIENT_MCPCLIENT_ARCHIVEMATICACLIENTMODULES: "/src/MCPClient/lib/archivematicaClientModules"
      ARCHIVEMATICA_MCPCLIENT_MCPCLIENT_CLIENTSCRIPTSDIRECTORY: "/src/MCPClient/lib/clientScripts/"
      ARCHIVEMATICA_MCPCLIENT_MCPCLIENT_ELASTICSEARCHSERVER: "elasticsearch:9200"
      ARCHIVEMATICA_MCPCLIENT_MCPCLIENT_ELASTICSEARCHTIMEOUT: 100
      ARCHIVEMATICA_MCPCLIENT_MCPCLIENT_MCPARCHIVEMATICASERVER: "gearmand:4730"
      ARCHIVEMATICA_MCPCLIENT_MCPCLIENT_CLAMAV_SERVER: "clamavd:3310"
      ARCHIVEMATICA_MCPCLIENT_MCPCLIENT_INDEX_AIP_CONTINUE_ON_ERROR: "yes"
      ARCHIVEMATICA_MCPCLIENT_EMAIL_DEFAULT_FROM_EMAIL: "${AM_DEFAULT_FROM_EMAIL}"
    volumes:
      - "archivematica_pipeline_data:/var/archivematica/sharedDirectory:rw"
    links:
      - "fits"
      - "clamavd"
      # TODO Replace this with reference to AWS RDS hosted MySQL for QA
      - "mysql"
      - "gearmand"
      # TODO Replace this with reference to AWS hosted ElasticSearch for QA
      - "elasticsearch"
      - "archivematica-storage-service"

  archivematica-dashboard:
    image: '${REGISTRY}archivematica-dashboard:${AM_DASHBOARD_VERSION}'
    environment:
      FORWARDED_ALLOW_IPS: "*"  # Specific to Gunicorn
      AM_GUNICORN_ACCESSLOG: "${AM_GUNICORN_ACCESSLOG}"
      AM_GUNICORN_RELOAD: "${AM_GUNICORN_RELOAD}"
      AM_GUNICORN_RELOAD_ENGINE: "${AM_GUNICORN_RELOAD_ENGINE}"
      AM_GUNICORN_WORKERS: "${AM_GUNICORN_WORKERS}"
      DJANGO_SETTINGS_MODULE: "settings.local"
      ARCHIVEMATICA_DASHBOARD_DASHBOARD_DJANGO_SECRET_KEY: "12345"
      ARCHIVEMATICA_DASHBOARD_DASHBOARD_DJANGO_ALLOWED_HOSTS: "*"
      ARCHIVEMATICA_DASHBOARD_DASHBOARD_GEARMAN_SERVER: "gearmand:4730"
      ARCHIVEMATICA_DASHBOARD_DASHBOARD_ELASTICSEARCH_SERVER: "elasticsearch:9200"
      ARCHIVEMATICA_DASHBOARD_DASHBOARD_STORAGE_SERVICE_CLIENT_QUICK_TIMEOUT: "60"
      ARCHIVEMATICA_DASHBOARD_CLIENT_USER: "archivematica"
      ARCHIVEMATICA_DASHBOARD_CLIENT_PASSWORD: "demo"
      ARCHIVEMATICA_DASHBOARD_CLIENT_HOST: "mysql"
      ARCHIVEMATICA_DASHBOARD_CLIENT_DATABASE: "MCP"
      ARCHIVEMATICA_DASHBOARD_EMAIL_DEFAULT_FROM_EMAIL: "${AM_DEFAULT_FROM_EMAIL}"
    volumes:
      - "archivematica_pipeline_data:/var/archivematica/sharedDirectory:rw"
    expose:
      - "8000"
    links:
      # TODO Replace this with reference to AWS RDS hosted MySQL for QA
      - "mysql"
      - "gearmand"
      # TODO Replace this with reference to AWS hosted ElasticSearch for QA
      - "elasticsearch"
      - "archivematica-storage-service"

  archivematica-storage-service:
    image: '${REGISTRY}archivematica-storage-service:${AM_SS_VERSION}'
    environment:
      FORWARDED_ALLOW_IPS: "*"  # Specific to Gunicorn
      SS_GUNICORN_ACCESSLOG: "${SS_GUNICORN_ACCESSLOG}"
      SS_GUNICORN_RELOAD: "${SS_GUNICORN_RELOAD}"
      SS_GUNICORN_RELOAD_ENGINE: "${SS_GUNICORN_RELOAD_ENGINE}"
      SS_GUNICORN_WORKERS: "${SS_GUNICORN_WORKERS}"
      DJANGO_SECRET_KEY: "12345"
      DJANGO_SETTINGS_MODULE: "storage_service.settings.local"
      DJANGO_ALLOWED_HOSTS: "*"
      SS_DB_URL: "mysql://archivematica:demo@mysql/SS"
    volumes:
      - "archivematica_pipeline_data:/var/archivematica/sharedDirectory:rw"
      - "archivematica_storage_service_staging_data:/var/archivematica/storage_service:rw"
      - "archivematica_storage_service_location_data:/home:rw"
      - "${VOL_BASE}/qa/etc/rdss-create-storage-locations.py:/rdss/create-storage-locations.py:ro"
    expose:
      - "8000"
    links:
      # TODO Replace this with reference to AWS RDS hosted MySQL
      - "mysql"

  # TODO Change this to use AWS services for QA but still use mock for dev
  rdss-archivematica-channel-adapter-consumer:
    image: '${REGISTRY}rdss-archivematica-channel-adapter:${RDSS_CHANADAPTER_VERSION}'
    command: "consumer"
    environment:
      RDSS_ARCHIVEMATICA_ADAPTER_CONSUMER.BACKEND: "dynamodb"
      RDSS_ARCHIVEMATICA_ADAPTER_CONSUMER.DYNAMODB_TLS: "${RDSS_ADAPTER_DYNAMODB_TLS}"
      RDSS_ARCHIVEMATICA_ADAPTER_CONSUMER.DYNAMODB_ENDPOINT: "${RDSS_ADAPTER_DYNAMODB_ENDPOINT}"
      RDSS_ARCHIVEMATICA_ADAPTER_LOGGING.LEVEL: "debug"
      RDSS_ARCHIVEMATICA_ADAPTER_AMCLIENT.URL: "http://archivematica-dashboard:8000"
      RDSS_ARCHIVEMATICA_ADAPTER_AMCLIENT.USER: "test"
      RDSS_ARCHIVEMATICA_ADAPTER_AMCLIENT.KEY: "test"
      RDSS_ARCHIVEMATICA_ADAPTER_S3.ENDPOINT: "${RDSS_ADAPTER_S3_ENDPOINT}"
      RDSS_ARCHIVEMATICA_ADAPTER_S3.FORCE_PATH_STYLE: "true"
      RDSS_ARCHIVEMATICA_ADAPTER_S3.INSECURE_SKIP_VERIFY: "true"
      RDSS_ARCHIVEMATICA_ADAPTER_S3.ACCESS_KEY: "${RDSS_ADAPTER_S3_AWS_ACCESS_KEY}"
      RDSS_ARCHIVEMATICA_ADAPTER_S3.SECRET_KEY: "${RDSS_ADAPTER_S3_AWS_SECRET_KEY}"
      RDSS_ARCHIVEMATICA_ADAPTER_S3.REGION: "${RDSS_ADAPTER_S3_AWS_REGION}"
      RDSS_ARCHIVEMATICA_ADAPTER_BROKER.QUEUES.MAIN: "${RDSS_ADAPTER_QUEUE_INPUT}"
      RDSS_ARCHIVEMATICA_ADAPTER_BROKER.QUEUES.INVALID: "${RDSS_ADAPTER_QUEUE_INVALID}"
      RDSS_ARCHIVEMATICA_ADAPTER_BROKER.QUEUES.ERROR: "${RDSS_ADAPTER_QUEUE_ERROR}"
      RDSS_ARCHIVEMATICA_ADAPTER_BROKER.REPOSITORY.BACKEND: "dynamodb"
      RDSS_ARCHIVEMATICA_ADAPTER_BROKER.REPOSITORY.DYNAMODB_TLS: "${RDSS_ADAPTER_DYNAMODB_TLS}"
      RDSS_ARCHIVEMATICA_ADAPTER_BROKER.REPOSITORY.DYNAMODB_ENDPOINT: "${RDSS_ADAPTER_DYNAMODB_ENDPOINT}"
      RDSS_ARCHIVEMATICA_ADAPTER_BROKER.REPOSITORY.DYNAMODB_TABLE: "rdss_am_messages"
      RDSS_ARCHIVEMATICA_ADAPTER_BROKER.BACKEND: "kinesis"
      RDSS_ARCHIVEMATICA_ADAPTER_BROKER.KINESIS.TLS: "${RDSS_ADAPTER_KINESIS_TLS}"
      RDSS_ARCHIVEMATICA_ADAPTER_BROKER.KINESIS.ENDPOINT: "${RDSS_ADAPTER_KINESIS_ENDPOINT}"
      RDSS_ARCHIVEMATICA_ADAPTER_BROKER.KINESIS.TLS_DYNAMODB: "${RDSS_ADAPTER_DYNAMODB_TLS}"
      RDSS_ARCHIVEMATICA_ADAPTER_BROKER.KINESIS.ENDPOINT_DYNAMODB: "${RDSS_ADAPTER_DYNAMODB_ENDPOINT}"
      AWS_REGION: "${RDSS_ADAPTER_KINESIS_AWS_REGION}"
      AWS_ACCESS_KEY: "${RDSS_ADAPTER_KINESIS_AWS_ACCESS_KEY}"
      AWS_SECRET_KEY: "${RDSS_ADAPTER_KINESIS_AWS_SECRET_KEY}"
    links:
      - "archivematica-dashboard"
    volumes:
      - "archivematica_pipeline_data:/var/archivematica/sharedDirectory:rw"
    ports:
      - "6060" # See net/http/pprof

  # TODO Change this to use AWS services for QA but still use mock for dev
  rdss-archivematica-channel-adapter-publisher:
    image: '${REGISTRY}rdss-archivematica-channel-adapter:${RDSS_CHANADAPTER_VERSION}'
    command: "publisher"
    environment:
      RDSS_ARCHIVEMATICA_ADAPTER_LOGGING.LEVEL: "debug"
      RDSS_ARCHIVEMATICA_ADAPTER_BROKER.QUEUES.MAIN: "${RDSS_ADAPTER_QUEUE_OUTPUT}"
      RDSS_ARCHIVEMATICA_ADAPTER_BROKER.QUEUES.INVALID: "${RDSS_ADAPTER_QUEUE_INVALID}"
      RDSS_ARCHIVEMATICA_ADAPTER_BROKER.QUEUES.ERROR: "${RDSS_ADAPTER_QUEUE_ERROR}"
      RDSS_ARCHIVEMATICA_ADAPTER_BROKER.BACKEND: "kinesis"
      RDSS_ARCHIVEMATICA_ADAPTER_BROKER.KINESIS.TLS: "${RDSS_ADAPTER_KINESIS_TLS}"
      RDSS_ARCHIVEMATICA_ADAPTER_BROKER.KINESIS.ENDPOINT: "${RDSS_ADAPTER_KINESIS_ENDPOINT}"
      AWS_REGION: "${RDSS_ADAPTER_KINESIS_AWS_REGION}"
      AWS_ACCESS_KEY: "${RDSS_ADAPTER_KINESIS_AWS_ACCESS_KEY}"
      AWS_SECRET_KEY: "${RDSS_ADAPTER_KINESIS_AWS_SECRET_KEY}"
    links:
      - "archivematica-dashboard"
    ports:
      - "6060" # See net/http/pprof

  # TODO Change this to use AWS service for QA but still use mock for dev
  rdss-archivematica-msgcreator:
    image: '${REGISTRY}rdss-archivematica-msgcreator:${RDSS_MSGCREATOR_VERSION}'
    command: "-addr=0.0.0.0:8000 -prefix=/msgcreator -kinesis-endpoint='${RDSS_ADAPTER_KINESIS_ENDPOINT}' -kinesis-stream='${RDSS_ADAPTER_QUEUE_INPUT}' -kinesis-region='${RDSS_ADAPTER_KINESIS_AWS_REGION}' -s3-access-key='${RDSS_ADAPTER_S3_AWS_ACCESS_KEY}' -s3-secret-key='${RDSS_ADAPTER_S3_AWS_SECRET_KEY}' -s3-region='${RDSS_ADAPTER_S3_AWS_REGION}' -s3-endpoint='${RDSS_ADAPTER_S3_ENDPOINT}' -checksums"
    expose:
      - "8000"

  nextcloud:
    image: "${REGISTRY}nextcloud:${NEXTCLOUD_VERSION}"
    hostname: "nextcloud"
    domainname: "${DOMAIN_NAME}"
    environment:
      ADMIN_USER: "astoradmin"
      ADMIN_PASSWORD: "arkivum"
      DB_HOST: "mysql"
      DB_USER: "root"
      DB_PASSWORD: "12345"
      DB_PORT: "3306"
      DB_TYPE: "mysql"
      GID: "${NEXTCLOUD_RUNAS_GID}"
      UID: "${NEXTCLOUD_RUNAS_UID}"
      EXTERNAL_STORAGES: "archivematica-aips:/mnt/am-pipeline-data/www/AIPsStore \
        archivematica-dips:/mnt/am-pipeline-data/www/DIPsStore \
        archivematica-processing-config:/mnt/am-pipeline-data/sharedMicroServiceTasksConfigs/processingMCPConfigs \
        arkivum-storage:/mnt/astor/aipingest \
        automated-transfer:/mnt/am-ss-default-location-data/automated \
        interactive-transfer:/mnt/am-ss-default-location-data/interactive \
        s3-jisc-test-research:/mnt/jisc-test-research-data"
    volumes:
      # Nextcloud app volumes
      - "nextcloud_data:/var/lib/nextcloud"
      - "nextcloud_themes:/nextcloud/themes"
      # External storage locations
      - "archivematica_pipeline_data:/mnt/am-pipeline-data"
      - "archivematica_storage_service_location_data:/mnt/am-ss-default-location-data"
      - "arkivum-storage:/mnt/astor/"
      - "jisc-test-research-data:/mnt/jisc-test-research-data"
    ports:
      - "${NEXTCLOUD_EXTERNAL_IP}:${NEXTCLOUD_EXTERNAL_PORT}:8888"
    depends_on:
      - "mysql"
      - "redis"
    links:
      - "mysql"
      - "redis"
